{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from functools import lru_cache\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, Ridge\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAND = 123\n",
    "PATH_TO_DATA = 'data/'\n",
    "PATH_TO_SUBMIT = 'submissions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions.csv'), index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(PATH_TO_DATA + \"site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "site_by_ind = [None] * (len(site_dict) + 1)\n",
    "for site, id in site_dict.items():\n",
    "    site_by_ind[id] = site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_name = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times_name] = train_df[times_name].apply(pd.to_datetime)\n",
    "test_df[times_name] = test_df[times_name].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sites_name = ['site{}'.format(i) for i in range(1, 11)]\n",
    "train_df[sites_name] = train_df[sites_name].fillna(0).astype('int')\n",
    "test_df[sites_name] = test_df[sites_name].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(by='time1')\n",
    "test_df = test_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "train_df = train_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_df, small_y = train_df[4000:4500], y[4000:4500]\n",
    "sum(small_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file, index=None,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    if index is None:\n",
    "        index = np.arange(1, predicted_labels.shape[0] + 1)\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = index,\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(PATH_TO_SUBMIT + '/' + out_file, index_label=index_label)\n",
    "    \n",
    "def submit(model, X, y, X_test, name='submit'):\n",
    "    for ind in range(1, 1000):\n",
    "        name_with_ind = name + '_' + str(ind)\n",
    "        if name_with_ind not in os.listdir(PATH_TO_SUBMIT):\n",
    "            name = name_with_ind\n",
    "            break\n",
    "    print(name)\n",
    "    X, X_test, transformers = train_test_features(X, y, X_test)\n",
    "    model.fit(X, y)\n",
    "    predict = model.predict_proba(X_test)[:,1]\n",
    "    log(X=X, model=model, status='submit {}'.format(name))\n",
    "    write_to_submission_file(predict, name, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generete_bag_of_sites(data):\n",
    "    full_sites = data[sites_name]\n",
    "    sites_flatten = full_sites.values.flatten()\n",
    "    full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                    sites_flatten,\n",
    "                                    range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]\n",
    "    return full_sites_sparse\n",
    "\n",
    "def generete_text_of_sites(data):\n",
    "    full_sites = data[sites_name]\n",
    "    return full_sites.apply(lambda x: '#'.join(site_by_ind[site] \n",
    "                                               for site in filter(lambda y: y, x)), axis=1)\n",
    "\n",
    "nano_in_min = 10**9 * 60\n",
    "bool_to_int = {True: 1, False: 0}\n",
    "\n",
    "def one_hot_smooth_encode(val, max_val):\n",
    "    result = np.zeros(max_val)\n",
    "    ival = int(val)\n",
    "    result[ival] += 1 - (val - ival)\n",
    "    result[(ival + 1) % max_val] += (val - ival)\n",
    "    return pd.Series(result)\n",
    "\n",
    "def encode_time(data, smooth=3, max_time=24, prefix=''):\n",
    "    max_val = (max_time + smooth - 1) // smooth\n",
    "    \n",
    "    def encode(x):\n",
    "        return one_hot_smooth_encode(x / smooth, max_val)\n",
    "    \n",
    "    result = data.apply(encode)\n",
    "    result = result.rename(columns={ind: prefix + str(ind) \n",
    "                                    for ind in range(max_val)})\n",
    "    return result\n",
    "\n",
    "def generate_cat_time_features(data):\n",
    "    full_times = data[times_name]\n",
    "    start_time = full_times['time1']\n",
    "    features = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    hours = start_time.apply(lambda x: x.hour + x.minute / 60)\n",
    "    \n",
    "    features['is_morning'] = ((hours > 6) & (hours <= 11)).map(bool_to_int)\n",
    "    features['is_day'] = ((hours > 11) & (hours <= 17)).map(bool_to_int)\n",
    "    features['is_evning'] = ((hours > 17) & (hours <= 24)).map(bool_to_int)\n",
    "    features['is_nignt'] = ((hours >= 0) & (hours <= 6)).map(bool_to_int)\n",
    "    \n",
    "    smooth_hours = 1\n",
    "    features = pd.concat([features, \n",
    "                          encode_time(hours, \n",
    "                                      prefix='smooth{}_hours_'.format(smooth_hours), \n",
    "                                      smooth=smooth_hours)], axis=1)\n",
    "     \n",
    "    #month = full_times['time1'].apply(lambda x: x.month)\n",
    "    #features = pd.concat([features, \n",
    "    #                      encode_time(month - 1, prefix='smooth2_month_', smooth=4, max_time=12)], axis=1)\n",
    "    \n",
    "    dayofweek = pd.get_dummies(start_time.apply(lambda x: x.dayofweek), prefix='day')\n",
    "    features = pd.concat([features, dayofweek], axis=1)\n",
    "    \n",
    "    features['is_day_off'] = (5 <= start_time.apply(lambda x: x.dayofweek)).map(bool_to_int)\n",
    "    \n",
    "    features.DESCRIPTION = ' '.join(features.columns)\n",
    "    return features\n",
    "\n",
    "def generate_count_time_features(data):\n",
    "    full_times = data[times_name]\n",
    "    start_time = full_times['time1']\n",
    "    features = pd.DataFrame(index=data.index)\n",
    "\n",
    "    features['month'] = start_time.apply(lambda x: x.month)\n",
    "    #features['year'] = start_time.apply(lambda x: x.year + x.month / 12)\n",
    "    features['trand_10000_100_1'] = start_time.apply(lambda x: x.year * 10000 + x.month * 100 + x.day)\n",
    "    #features['trand_log_10000_100_1'] = start_time.apply(lambda x: np.log(x.year * 10000 + x.month * 100 + x.day))\n",
    "    #features['trand_1000_100_1'] = start_time.apply(lambda x: x.year * 1000 + x.month * 100 + x.day)\n",
    "    \n",
    "    seconds_from_start = train_df[times_name].\\\n",
    "        applymap(lambda x: np.nan if pd.isnull(x) else x.value)\n",
    "    features['duration'] = (seconds_from_start.max(1) - seconds_from_start.min(1)) / nano_in_min\n",
    "    #features['sites_count'] = (~full_times.isnull()).sum(1)\n",
    "    #features['mean_duration'] = features['duration'] / features['sites_count']\n",
    "    \n",
    "    features.DESCRIPTION = ' '.join(features.columns)\n",
    "    return features\n",
    "\n",
    "def generate_y_prob(text, y, vocab, alpha=10):\n",
    "    n = len(vocab)\n",
    "    good_count = np.zeros(n + 1)\n",
    "    count = np.zeros(n + 1)\n",
    "    for session, is_good in zip(text, y):\n",
    "        for site in session.split('#'):\n",
    "            ind = vocab.get(site, n)\n",
    "            count[ind] += 1\n",
    "            if is_good == 1:\n",
    "                good_count[ind] += 1\n",
    "    global_mean = good_count.sum() / count.sum()\n",
    "    prob = (good_count + global_mean * alpha) / (count + alpha)\n",
    "    return csr_matrix([prob[:-1]])\n",
    "\n",
    "def generate_all_features(data, y=None, transformers=None, X_test=None):\n",
    "    description = ''\n",
    "    X_cat_time = generate_cat_time_features(data)\n",
    "    X_count_time = generate_count_time_features(data)\n",
    "    X_text = generete_text_of_sites(data)\n",
    "    \n",
    "    description += 'Features_cat_time: {}\\n'.format(X_cat_time.DESCRIPTION)\n",
    "    description += 'Features_count_time: {}\\n'.format(X_count_time.DESCRIPTION)\n",
    "    \n",
    "    if not transformers:\n",
    "        transformers = {}\n",
    "    if 'vecorizer' not in transformers:\n",
    "        #transformers['vecorizer'] = TfidfVectorizer(max_features=10000,\n",
    "        #                                            analyzer='word', \n",
    "        #                                            token_pattern='[^#]+').fit(X_text)\n",
    "        #vocab = transformers['vecorizer'].vocabulary_\n",
    "        #transformers['y_prob'] = generate_y_prob(X_text, y, vocab)\n",
    "        \n",
    "        if X_test is not None:\n",
    "            text_test = generete_text_of_sites(X_test)\n",
    "            all_text = pd.concat((X_text, text_test))\n",
    "        else:\n",
    "            all_text = X_text\n",
    "        transformers['vecorizer'] = TfidfVectorizer(max_features=8500,\n",
    "                                                    analyzer='word', \n",
    "                                                    token_pattern='[^#]+').fit(all_text)\n",
    "    X_text_csr = transformers['vecorizer'].transform(X_text)\n",
    "    description += '{}: {}\\n'.format('vecorizer Train+Test', transformers['vecorizer'])\n",
    "    \n",
    "    \n",
    "    if 'TfidfTransformer' not in transformers:\n",
    "        if X_test is not None:\n",
    "            cat_test = generate_cat_time_features(X_test)\n",
    "            all_cat = pd.concat((X_cat_time, cat_test))\n",
    "        else:\n",
    "            all_cat = X_cat_time\n",
    "        transformers['TfidfTransformer'] = TfidfTransformer().fit(X_cat_time)  \n",
    "    X_cat_time_csr = csr_matrix(transformers['TfidfTransformer'].transform(X_cat_time))\n",
    "    description += '{}: {}\\n'.format('transformer X_cat_time', transformers['TfidfTransformer'])\n",
    "    \n",
    "    \n",
    "    if 'scaler' not in transformers:\n",
    "        transformers['scaler'] = StandardScaler().fit(X_count_time)\n",
    "    X_count_time_csr = csr_matrix(\n",
    "        transformers['scaler'].transform(X_count_time))\n",
    "    description += '{}: {}\\n'.format('scaler for count', transformers['scaler'])\n",
    "\n",
    "    #X_text_csr = X_text_csr.multiply(transformers['y_prob'])\n",
    "    #description += 'y_prob\\n'\n",
    "    \n",
    "    result = hstack((X_cat_time_csr, X_count_time_csr, X_text_csr)).tocsc()\n",
    "    \n",
    "    result.DESCRIPTION = description\n",
    "    result.ANOTATION = X_cat_time.columns.tolist()\n",
    "    result.ANOTATION += X_count_time.columns.tolist()\n",
    "    return result, transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.5\n",
    "    \n",
    "\n",
    "def log(file_name='temp_results.txt', last_action_file_name='last_action.txt',\n",
    "        X=None, model=None, score=None, status=None):\n",
    "    log_str = 'Status: {}\\n'.format(status)\n",
    "    if score is not None:\n",
    "        log_str += 'Score = {}\\n\\n'.format(score)\n",
    "    if model is not None:\n",
    "        log_str += 'Model:\\n{}\\n\\n'.format(model)\n",
    "    if X is not None:\n",
    "        log_str += 'Features:\\n{}\\n'.format(X.DESCRIPTION)\n",
    "    \n",
    "    with open(file_name, 'a') as fl:\n",
    "        fl.write('-'*100 + '\\n');\n",
    "        fl.write(log_str)\n",
    "    \n",
    "    with open(last_action_file_name, 'w') as fl:\n",
    "        fl.write(log_str)\n",
    "        \n",
    "    return log_str\n",
    "\n",
    "\n",
    "def train_test_features(X_train, y_train, X_test):\n",
    "    X_train, transformers = generate_all_features(X_train, y=y_train, X_test=X_test)\n",
    "    X_test, transformers = generate_all_features(X_test, transformers=transformers)\n",
    "    return X_train, X_test, transformers\n",
    "\n",
    "\n",
    "def train_test_features_split(X, y, return_transformers=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=TEST_SIZE)\n",
    "    X_train, X_test, transformers = train_test_features(X_train, y_train, X_test)\n",
    "    if return_transformers:\n",
    "        return X_train, X_test, y_train, y_test, transformers\n",
    "    else:\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def score(model, X, y, X_test=None, y_test=None, write_log=True):\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    if X_test is None and y_test is None: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=TEST_SIZE)\n",
    "        X_train, X_test, _ = train_test_features(X_train, y_train, X_test)\n",
    "        \n",
    "    predict = model.predict_proba(X_test)[:,1]\n",
    "    auc_score = roc_auc_score(y_test, predict)\n",
    "    \n",
    "    if write_log:\n",
    "        log(model=model, score=auc_score, status='score', X=X)\n",
    "        \n",
    "    return auc_score\n",
    "\n",
    "\n",
    "def cross_score(model, X, y, n_splits=8, n_test=3, write_log=True):\n",
    "    l = len(y) // n_splits\n",
    "    auc_score = np.array([score(model, \n",
    "                                X[i*l:(i+n_test)*l], y[i*l:(i+n_test)*l],\n",
    "                                X[(i+n_test+1)*l:], y[(i+n_test+1)*l:],\n",
    "                                write_log=False)\n",
    "                          for i in range(n_splits - n_test - 1)])\n",
    "    if write_log:\n",
    "        log(model=model, score=auc_score, status='score my fold: {}'.format((n_splits, n_test)), X=X)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 1.17 s, total: 1min 38s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, transformers = generate_all_features(train_df, y=y, X_test=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943312635078\n",
      "[ 0.91901113  0.94178664  0.95589899  0.95655378]\n",
      "Diff with last: 0.014548849201931224\n",
      "Diff with best: -0.006638073251232335\n",
      "CPU times: user 4.14 s, sys: 1.29 s, total: 5.43 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(C=2, random_state=RAND)\n",
    "#model = BaggingClassifier(model, n_estimators=20, n_jobs=-1, random_state=RAND)\n",
    "arr_score = cross_score(model, X, y, n_splits=7, n_test=2)\n",
    "\n",
    "new_score = arr_score.mean()\n",
    "print(new_score)\n",
    "print(arr_score)\n",
    "\n",
    "print('Diff with last: {}'.format(new_score - last_score))\n",
    "print('Diff with best: {}'.format(new_score - last_best_score))\n",
    "last_score = new_score\n",
    "if last_best_score < new_score:\n",
    "    last_best_score = new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.949931835196\n",
    "[ 0.9407109   0.94513859  0.95732408  0.95655378]\n",
    "Diff with last: 0.0\n",
    "Diff with best: 0.0\n",
    "CPU times: user 4.75 s, sys: 1.95 s, total: 6.7 s\n",
    "Wall time: 3.55 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-757fd3ea3e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANOTATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcount_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "new_features = X.ANOTATION\n",
    "count_features = len(new_features)\n",
    "if type(model) is LogisticRegression:\n",
    "    coef = model.coef_[0]\n",
    "else:\n",
    "    coef = np.array([m.coef_[0] for m in model.estimators_]).mean(0)\n",
    "argsort_coef = np.argsort(np.abs(coef))\n",
    "argsort_features = np.argsort(np.abs(coef[:count_features]))[::-1]\n",
    "\n",
    "print('Total', len(coef))\n",
    "for ind_feature in argsort_features:\n",
    "    name = new_features[ind_feature]\n",
    "    value = coef[ind_feature]\n",
    "    num = argsort_coef[ind_feature]\n",
    "    print('{:7.2f} {:5} {}'.format(value, num, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit(model, train_df, y, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
