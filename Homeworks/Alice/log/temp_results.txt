----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9305384921258488

Model:
LogisticRegression(C=0.7, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: submit submit_1
Model:
LogisticRegression(C=0.7, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9290849173261626

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9290849173261626

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9317503844025424

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9219175762979731

Model:
LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9306731827489703

Model:
LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9324390802841412

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: submit submit_2
Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=6000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9324432527988722

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9317419931828808

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9140736489189446

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9292407630608718

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.880671036444345

Model:
LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9331936818827345

Model:
LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9336306488728466

Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9331076680320182

Model:
LogisticRegression(C=0.15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9335024941630214

Model:
LogisticRegression(C=0.25, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9336306488728466

Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: submit submit_3
Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.7410212332961994

Model:
LogisticRegression(C=0.0001, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=123,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)

Features:
Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9380967834256253

Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9380967834256253

Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9386473265414901

Model:
LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9387789846536174

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9387174146851764

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9387681840964881

Model:
LogisticRegression(C=0.45, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9387792291945336

Model:
LogisticRegression(C=0.41, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9387779385619206

Model:
LogisticRegression(C=0.42, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9387792291945336

Model:
LogisticRegression(C=0.41, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: submit submit_4
Model:
LogisticRegression(C=0.41, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=15000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9384356831713762

Model:
LogisticRegression(C=0.41, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9383678502383609

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9374979502716265

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9203286646215619

Model:
LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9360205970835995

Model:
LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9383678502383609

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9382552934889052

Model:
LogisticRegression(C=0.6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9384355201440987

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9384156579874657

Model:
LogisticRegression(C=0.45, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9321934638180114

Model:
LogisticRegression(C=0.45, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9303982074390051

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.8927599844222003

Model:
LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.928306920695408

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9272737828743487

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.928889559806516

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9296652707637179

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9319433324248185

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9318854781197422

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9319433324248185

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: submit submit_5
Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9378477524665552

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9333197513497096

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9378477524665552

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9379715309269402

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9379616270198365

Model:
LogisticRegression(C=0.41, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9379142404245318

Model:
LogisticRegression(C=0.45, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9379282471847838

Model:
LogisticRegression(C=0.44, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9379351486728614

Model:
LogisticRegression(C=0.44, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: submit submit_6
Model:
LogisticRegression(C=0.44, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt is_day_off duration sites_count mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.93753423742646

Model:
LogisticRegression(C=0.44, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9374283240385595

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9376028447390432

Model:
LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9373322873865496

Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9376119878521855

Model:
LogisticRegression(C=0.35, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9376094745149918

Model:
LogisticRegression(C=0.36, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9376119878521855

Model:
LogisticRegression(C=0.35, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_day is_evning is_day_off mean_duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9581699245267936

Model:
LogisticRegression(C=0.35, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9587271789322458

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9593423351923969

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9587610342635243

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9593423351923969

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: submit submit_7
Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9593070262012278

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9594108338201283

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9592476435154257

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9593488426978873

Model:
LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour_7 hour_8 hour_9 hour_10 hour_11 hour_12 hour_13 hour_14 hour_15 hour_16 hour_17 hour_18 hour_19 hour_20 hour_21 hour_22 hour_23 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9585855965346053

Model:
LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9546193874157668

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9587639076192891

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9590736458607904

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9591278931873535

Model:
LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9591685413218584

Model:
LogisticRegression(C=8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9590195072190788

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: submit submit_8
Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9085220050279242

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.909489911559604

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9094651178278289

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9060300244076289

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.906202609159193

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9423438817506642

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9257288480870257

Model:
LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9495513584424504

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9516238970491437

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9533031595202618

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.954737731633571

Model:
LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.954972422985031

Model:
LogisticRegression(C=150, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9533437533123407

Model:
LogisticRegression(C=650, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9556874334526049

Model:
LogisticRegression(C=350, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.953619052041486

Model:
LogisticRegression(C=250, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9556874334526049

Model:
LogisticRegression(C=350, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: submit submit_9
Model:
LogisticRegression(C=350, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=20000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.952230677782917

Model:
LogisticRegression(C=350, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='[^#]+', tokenizer=None,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9496835396004262

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='[^#]+', tokenizer=None,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9507172955665791

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='[^#]+', tokenizer=None,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: submit submit_10
Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='[^#]+', tokenizer=None,
        vocabulary=None)
y_prob
Features_time: is_morning is_day is_evning is_nignt hour/2_3 hour/2_4 hour/2_5 hour/2_6 hour/2_7 hour/2_8 hour/2_9 hour/2_10 hour/2_11 month dayofweek is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9468404118101633

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9400946555392579

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9468404118101633

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9459446312631377

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9427711151095666

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9468404118101633

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9468726640398806

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9463666681275722

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9468726640398806

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: submit submit_11
Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9317599842657703

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9337149151943309

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9363954633710021

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9353067680560032

Model:
LogisticRegression(C=0.41, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.937736557335387

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)
vecorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9384068849141298

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration sites_count mean_duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9367231905381778

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration sites_count mean_duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9411079030477556

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration sites_count mean_duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9409674386496375

Model:
LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration sites_count mean_duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9408471670672743

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9390689983356438

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9406131521174773

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9401780558304642

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9408200457215233

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9326642575090098

Model:
LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=100000, min_df=1,
        ngram_range=(2, 4), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='(?u)\\b\\w\\w+\\b', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9399891302142077

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9403561036546271

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9356712318288907

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9400308168696834

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9401527743943456

Model:
LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9403561036546271

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9452744125400364

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9406526028106391

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9444854963733632

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9452850636554948

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9450097513407432

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9452744125400364

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_12
Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_time: is_morning is_day is_evning is_nignt hour/3_2 hour/3_3 hour/3_4 hour/3_5 hour/3_6 hour/3_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 month is_day_off
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9521243500340197

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9442165217440213

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9524300669360113

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9524845316322776

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9523019139103486

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9524237360434046

Model:
LogisticRegression(C=25, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9524845316322776

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_13
Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt hours_0 hours_1 hours_2 hours_3 hours_4 hours_5 hours_6 hours_7 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9501174842489157

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9476090378736005

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9500634135352364

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9500634135352364

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9500634135352364

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9476090378736005

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9500634135352364

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9502794654346441

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9491865849092116

Model:
LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9502794654346441

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_14
Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.952430814144366

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9564820691595947

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.953439083512815

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9551950231467486

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9545589314670551

Model:
LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9551950231467486

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9558828624014184

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9423084825192998

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9423084825192998

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9420936907642237

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9421945169952601

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9419957544756374

Model:
LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.937751014024645

Model:
LogisticRegression(C=400, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9310975123913596

Model:
LogisticRegression(C=4000, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9315563931318588

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9315563931318588

Model:
LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9389785375557381

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9412997639022319

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9420936907642237

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9422814668224662

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9423084825192998

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.942281905578911

Model:
LogisticRegression(C=25, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9422962733899598

Model:
LogisticRegression(C=23, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9423040949548509

Model:
LogisticRegression(C=22, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9535303955072825

Model:
LogisticRegression(C=22, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9535303955072825

Model:
LogisticRegression(C=22, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9532976276928848

Model:
LogisticRegression(C=25, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9541243937805697

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9497338459090618

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9422558065007534

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9520603115602893

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9523739391689231

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.950968891023492

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=3000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9440128047240626

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9499532955491339

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9489971122194911

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9493400205657246

Model:
LogisticRegression(C=25, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9502062561792866

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9462961094825987

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9501032905251798

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9502062561792866

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9502714613449152

Model:
LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9539190013580227

Model:
LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9540223365337291

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9537274582971009

Model:
LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score
Score = 0.9538978154529683

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score StratifiedKFold: StratifiedKFold(n_splits=3, random_state=None, shuffle=False)
Score = 0.9168758192544332

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score StratifiedKFold: StratifiedKFold(n_splits=3, random_state=None, shuffle=False)
Score = 0.9168758192544332

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score StratifiedKFold: StratifiedKFold(n_splits=4, random_state=None, shuffle=False)
Score = 0.9222564394047993

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score StratifiedKFold: KFold(n_splits=4, random_state=None, shuffle=False)
Score = 0.9142196518302707

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score StratifiedKFold: KFold(n_splits=5, random_state=None, shuffle=False)
Score = [ 0.89355598  0.92364756  0.96898725  0.96175348  0.96021576]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (5, 3)
Score = [ 0.92540775  0.97047763  0.96873655]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (5, 3)
Score = [ 0.93865978  0.96032418]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (5, 3)
Score = [ 0.93865978  0.96032418]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.87534784  0.95290745  0.97513806  0.93962193]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.87534784  0.95290745  0.97513806  0.93962193]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.87534784  0.95290745  0.97513806  0.93962193]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 4)
Score = [ 0.96796935  0.95997547  0.95104991]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 4)
Score = [ 0.96796935  0.95997547  0.95104991]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 4)
Score = [ 0.93491599  0.94334024  0.96681323  0.95904817]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 4)
Score = [ 0.94621045  0.93643457  0.95104991]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 4)
Score = [ 0.94621045  0.93643457  0.95104991]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.92434799  0.94021579  0.95338225  0.93962193]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.93491599  0.94334024  0.96681323  0.95904817]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.91861134  0.93379805  0.95657907  0.96686573  0.95585437]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92434799  0.94021579  0.95338225  0.93962193]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.94621045  0.93643457  0.95104991]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.94621045  0.93643457  0.95104991]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94605361  0.94821284  0.96056228  0.94920761]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 2)
Score = [ 0.91123413  0.95873366  0.94359023  0.95414897  0.95558406]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94605361  0.94821284  0.96056228  0.94920761]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 4)
Score = [ 0.94244042  0.95377875  0.95218716]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 4)
Score = [ 0.94244042  0.95377875  0.95218716]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94605361  0.94821284  0.96056228  0.94920761]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94546658  0.94973977  0.96027374  0.95106596]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94605361  0.94821284  0.96056228  0.94920761]

Model:
LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94610689  0.94894934  0.96063886  0.95007535]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94610689  0.94894934  0.96063886  0.95007535]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_15
Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.94301936  0.94925773]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.94301936  0.94925773]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.94301936  0.94925773]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.95092866  0.95500604]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.95092866  0.95500604  0.96361908]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 4)
Score = [ 0.95421825  0.95637688]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 2)
Score = [ 0.93184134  0.93163623  0.96726635  0.96371527]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 2)
Score = [ 0.93184134  0.93163623  0.96726635  0.96371527]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.93263728  0.95202714  0.96534879  0.96860988  0.9621126 ]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92385508  0.94132796  0.95307003  0.93927992]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94610689  0.94894934  0.96063886  0.95007535]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (10, 3)
Score = [ 0.92569565  0.95580099  0.94180544  0.96569038  0.95779563  0.98649101]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (10, 4)
Score = [ 0.94668081  0.94975274  0.95744627  0.96090753  0.98357187]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (5, 2)
Score = [ 0.94070467  0.96183146]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (5, 1)
Score = [ 0.91012466  0.95067684  0.97063402]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 2)
Score = [ 0.9451954   0.91650303  0.96026263]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92385508  0.94132796  0.95307003  0.93927992]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92385508  0.94132796  0.95307003  0.93927992]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.94615917  0.93685204  0.95225442]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (8, 3)
Score = [ 0.94610689  0.94894934  0.96063886  0.95007535]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92385508  0.94132796  0.95307003  0.93927992]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93972024  0.94230447  0.95787207  0.94488756]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 smooth2_hours_12 smooth2_hours_13 smooth2_hours_14 smooth2_hours_15 smooth2_hours_16 smooth2_hours_17 smooth2_hours_18 smooth2_hours_19 smooth2_hours_20 smooth2_hours_21 smooth2_hours_22 smooth2_hours_23 smooth2_hours_24 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93262124  0.93949123  0.95441594  0.94402471]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth2_hours_0 smooth2_hours_1 smooth2_hours_2 smooth2_hours_3 smooth2_hours_4 smooth2_hours_5 smooth2_hours_6 smooth2_hours_7 smooth2_hours_8 smooth2_hours_9 smooth2_hours_10 smooth2_hours_11 smooth2_hours_12 smooth2_hours_13 smooth2_hours_14 smooth2_hours_15 smooth2_hours_16 smooth2_hours_17 smooth2_hours_18 smooth2_hours_19 smooth2_hours_20 smooth2_hours_21 smooth2_hours_22 smooth2_hours_23 smooth2_hours_24 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#.]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93820431  0.94124717  0.95573214  0.94685622]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94129028  0.94228875  0.95685926  0.94591694]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93820431  0.94124717  0.95573214  0.94685622]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_16
Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 smooth2_month_0 smooth2_month_1 smooth2_month_2 smooth2_month_3 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93938773  0.94420714  0.95726085  0.9528639 ]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038509  0.94510553  0.95785569  0.949976  ]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93850003  0.94208526  0.95593121  0.95315054]

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93969543  0.94474257  0.95756022  0.95257786]

Model:
LogisticRegression(C=1.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93969543  0.94474257  0.95756022  0.95257786]

Model:
LogisticRegression(C=1.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93985605  0.94498082  0.95767579  0.95236671]

Model:
LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94013649  0.94530965  0.95783884  0.95190872]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94039072  0.94546258  0.95790468  0.95112351]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94013649  0.94530965  0.95783884  0.95190872]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_17
Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93977602  0.94581345  0.95749124  0.9555642 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94013539  0.94602169  0.95776417  0.95427664]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93977602  0.94581345  0.95749124  0.9555642 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93881553  0.94460743  0.95664425  0.95692003]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93977602  0.94581345  0.95749124  0.9555642 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_18
Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93977602  0.94581345  0.95749124  0.9555642 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.95078047  0.94257174  0.96229373]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93977602  0.94581345  0.95749124  0.9555642 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 2)
Score = [ 0.95006113  0.9294095   0.96814394]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93977602  0.94581345  0.95749124  0.9555642 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.94924698  0.95799733]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94007084  0.94525995  0.95667254  0.94524221]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month year trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (6, 3)
Score = [ 0.9492595   0.95929197]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month year trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94007084  0.94525995  0.95667254  0.94524221]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month year trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94034472  0.94537857  0.95690536  0.94550125]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month year trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94035927  0.94497779  0.95703839  0.94541889]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month year trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94030683  0.94519205  0.9573794   0.95069208]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=125, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=124, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998282  0.9454051   0.95705023  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94080495  0.94517022  0.95681735  0.95128608]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=4000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90743144  0.91970937  0.94326709  0.9145053 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=100, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038807  0.94495751  0.95740371  0.95087108]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.3, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9398007   0.94412979  0.9564917   0.9506147 ]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.3, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94048433  0.94493719  0.95770126  0.95072432]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.3, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038183  0.94467556  0.95784707  0.95054627]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.3, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038807  0.94495751  0.95740371  0.95087108]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.3, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038807  0.94495751  0.95740371  0.95087108]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94048433  0.94493719  0.95770126  0.95072432]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038183  0.94467556  0.95784707  0.95054627]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94048433  0.94493719  0.95770126  0.95072432]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94048433  0.94493719  0.95770126  0.95072432]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94038807  0.94495751  0.95740371  0.95087108]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=5000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94071237  0.94527445  0.95722383  0.95013324]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94071237  0.94527445  0.95722383  0.95013324]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94124487  0.94537954  0.95755433  0.95027613]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94147873  0.94519764  0.95772091  0.9502285 ]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94156658  0.94491852  0.95781582  0.95016867]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.45, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94124886  0.94562248  0.95774072  0.95040596]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9410017   0.94573133  0.95757308  0.95027631]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94124886  0.94562248  0.95774072  0.95040596]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94135944  0.94539601  0.95783644  0.950448  ]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9413954   0.94514005  0.95790065  0.95044697]

Model:
LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94124886  0.94562248  0.95774072  0.95040596]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93887077  0.94559952  0.95617032  0.95051334]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=3, n_jobs=2, oob_score=False,
         random_state=None, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94145299  0.9445027   0.95467914  0.94772319]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=3, n_jobs=2, oob_score=False,
         random_state=None, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94098999  0.94456766  0.95838075  0.94998477]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=3, n_jobs=2, oob_score=False,
         random_state=None, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94045961  0.94543465  0.95194215  0.95325345]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=5, n_jobs=-1, oob_score=False,
         random_state=None, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94169405  0.9455497   0.95794274  0.9520394 ]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_19
Model:
BaggingClassifier(base_estimator=LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94045798  0.94554969  0.95722455  0.94998683]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=0.35, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93998814  0.94540514  0.95705021  0.95093333]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94013649  0.94530965  0.95783884  0.95190872]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 smooth1_hours_24 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94013638  0.94530963  0.95783862  0.95190872]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94011729  0.9445525   0.95839541  0.94662116]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94039433  0.94469381  0.95832903  0.9449541 ]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93922849  0.94355958  0.95804263  0.94919156]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93989685  0.94320928  0.95767457  0.93982681]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93922849  0.94355958  0.95804263  0.94919156]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94046392  0.94457876  0.95820644  0.94371529]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94039433  0.94469381  0.95832903  0.9449541 ]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94033495  0.94543514  0.9575354   0.95052761]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_log_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94039612  0.94469552  0.95832877  0.94495711]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_100_10_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94027849  0.94549767  0.95709902  0.95030752]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_1000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94031005  0.9451238   0.9572222   0.95010023]

Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_1000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93920327  0.94427704  0.95609753  0.94963046]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_1000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94027849  0.94549767  0.95709902  0.95030752]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 trand_1000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93955667  0.94532843  0.95751368  0.94994496]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93919139  0.94504072  0.95738309  0.95075467]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93710001  0.9412321   0.95515871  0.95228976]

Model:
LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93551426  0.93649822  0.95420163  0.940248  ]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94039098  0.94546259  0.95789828  0.95112351]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94013638  0.94530963  0.95783862  0.95190872]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94087255  0.94517458  0.95798969  0.95103315]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94137337  0.94528329  0.9581973   0.95039143]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94158259  0.94509851  0.95827561  0.94988306]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93984915  0.93943459  0.95724334  0.94562832]

Model:
LogisticRegression(C=35, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94150035  0.94520407  0.95824079  0.95011364]

Model:
LogisticRegression(C=3.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94137337  0.94528329  0.9581973   0.95039143]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94085031  0.94572645  0.95863723  0.9516391 ]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94115295  0.94594509  0.95857679  0.95178027]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=30, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94110351  0.94555309  0.95826989  0.95000428]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94131732  0.94543006  0.95834854  0.94957707]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94058473  0.94536496  0.95804726  0.95058599]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94110351  0.94555309  0.95826989  0.95000428]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93945423  0.94417491  0.95726614  0.95130741]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=10000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94117323  0.94552154  0.95827655  0.95056725]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94137398  0.94537124  0.95835251  0.95009868]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94069381  0.94536905  0.95808065  0.95117836]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93958325  0.94422991  0.95730986  0.95189823]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94069381  0.94536905  0.95808065  0.95117836]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94098396  0.94550096  0.95820522  0.95086343]

Model:
LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94114766  0.94552205  0.95826402  0.95062304]

Model:
LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94117323  0.94552154  0.95827655  0.95056725]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94114766  0.94552205  0.95826402  0.95062304]

Model:
LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94091759  0.94621642  0.95860781  0.95206364]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=30, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94072121  0.94599002  0.9586052   0.95190442]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=40, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94100983  0.94592136  0.95862044  0.95227695]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94131492  0.94565958  0.95863454  0.95161829]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93966527  0.94451658  0.95781823  0.95326738]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94063769  0.945723    0.95846896  0.95265137]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94104177  0.94592451  0.95862452  0.95224402]

Model:
BaggingClassifier(base_estimator=LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_20
Model:
BaggingClassifier(base_estimator=LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
         bootstrap=True, bootstrap_features=False, max_features=1.0,
         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,
         random_state=123, verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94117323  0.94552154  0.95827655  0.95056725]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_21
Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94114766  0.94552205  0.95826402  0.95062304]

Model:
LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94098396  0.94550096  0.95820522  0.95086343]

Model:
LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94110465  0.94552542  0.95825102  0.95068194]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94105563  0.94562526  0.95819166  0.95045866]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94062301  0.94543759  0.958003    0.95085415]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94135442  0.94551142  0.9583093   0.95000454]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94113043  0.94562102  0.9582207   0.95036753]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94116581  0.94561749  0.9582342   0.95032325]

Model:
LogisticRegression(C=3.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94113043  0.94562102  0.9582207   0.95036753]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94116581  0.94561749  0.9582342   0.95032325]

Model:
LogisticRegression(C=3.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94119883  0.94561329  0.95824839  0.95028972]

Model:
LogisticRegression(C=3.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94122005  0.9456053   0.95826071  0.95025946]

Model:
LogisticRegression(C=3.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94119883  0.94561329  0.95824839  0.95028972]

Model:
LogisticRegression(C=3.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_22
Model:
LogisticRegression(C=3.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=9000, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94123367  0.94499829  0.95777931  0.9499925 ]

Model:
LogisticRegression(C=3.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94136733  0.94482518  0.95776996  0.94951173]

Model:
LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94118658  0.94502027  0.95777764  0.95011691]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94099964  0.94503854  0.95775612  0.95046726]

Model:
LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407804   0.94496561  0.95771117  0.95078674]

Model:
LogisticRegression(C=2.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94090284  0.94501717  0.95773387  0.95062623]

Model:
LogisticRegression(C=2.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94094914  0.94502768  0.95774883  0.95054171]

Model:
LogisticRegression(C=2.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94090284  0.94501717  0.95773387  0.95062623]

Model:
LogisticRegression(C=2.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_23
Model:
LogisticRegression(C=2.3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=7500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94117323  0.94552154  0.95827655  0.95056725]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94114766  0.94552205  0.95826402  0.95062304]

Model:
LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94110465  0.94552542  0.95825102  0.95068194]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94162978  0.94552979  0.95842488  0.95622699]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94152725  0.94554679  0.95833537  0.95639902]

Model:
LogisticRegression(C=2.6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94171036  0.94550814  0.95850734  0.95605357]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94162978  0.94552979  0.95842488  0.95622699]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94167274  0.94551949  0.95847881  0.95613396]

Model:
LogisticRegression(C=2.9, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94162978  0.94552979  0.95842488  0.95622699]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94162978  0.94552979  0.95842488  0.95622699]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9411135   0.94515552  0.9576558   0.95567219]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94116657  0.9451208   0.95770577  0.95548184]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9411135   0.94515552  0.9576558   0.95567219]

Model:
LogisticRegression(C=2.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94103343  0.94517594  0.95759407  0.95588567]

Model:
LogisticRegression(C=2.6, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94095008  0.94518476  0.95751466  0.95609106]

Model:
LogisticRegression(C=2.4, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94084449  0.94517503  0.95742853  0.95631159]

Model:
LogisticRegression(C=2.2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94055759  0.94506203  0.95720311  0.9568111 ]

Model:
LogisticRegression(C=1.8, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit submit_24
Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90806353  0.88390479  0.90817087  0.9190511 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90806353  0.88390479  0.90817087  0.9190511 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90806353  0.88390479  0.90817087  0.9190511 ]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9029634   0.87909189  0.90177989  0.91177082]

Model:
LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.91376656  0.89139921  0.91833979  0.92227689]

Model:
LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90335498  0.89076782  0.9271188   0.8956964 ]

Model:
LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.91285997  0.89376165  0.92523396  0.91011511]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=True,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90789928  0.88951535  0.92361104  0.91102558]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.90782679  0.88533092  0.90999148  0.91880607]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92870371  0.91691931  0.91895742  0.94107852]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93555465  0.92314273  0.93425751  0.94314364]

Model:
LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93187724  0.91505282  0.94028275  0.93428331]

Model:
LogisticRegression(C=300, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9346129   0.92026315  0.93906408  0.93974651]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.92501595  0.89393212  0.95322561  0.81918596]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93385081  0.91564513  0.95473376  0.90934632]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93740272  0.91564513  0.95473376  0.90934632]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93385081  0.93498473  0.95473376  0.94472051]

Model:
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94116657  0.9451208   0.95770577  0.95548184]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94116657  0.9451208   0.95770577  0.95548184]

Model:
LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94464204  0.95732408  0.95202203]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94497002  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94497002  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94071058  0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94063133  0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93927979  0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9407109   0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.93956352  0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94008391  0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94078639  0.94513859  0.95732408  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94074579  0.94066932  0.95589899  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94072697  0.94178664  0.95589899  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.86081696  0.94178664  0.95589777  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.91901113  0.94178664  0.95589899  0.95655378]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.94091269  0.9447346   0.95367928  0.96070414]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.9396574   0.94441808  0.95389262  0.96048542]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.75721285  0.94433947  0.95378829  0.96017058]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.74009317  0.7379435   0.59896827  0.83210484]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.7492166   0.94461497  0.95386808  0.96017084]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 2)
Score = [ 0.77019512  0.94518512  0.95398006  0.96097625]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.94657673  0.94378272  0.97335176]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.94619537  0.94580528  0.97581916]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score my fold: (7, 3)
Score = [ 0.94619353  0.9458345   0.97582123]

Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 2)
Score = [ 0.23471805  0.94697103  0.95197185  0.96387808]

Model:
(LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=300, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit two models lol2_1
Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit two models lol2_1
Model:
LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.94761686  0.9404834   0.97574737]

Model:
(LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=300, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.95104062  0.94034914  0.97414789]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=300, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.95199583  0.93911885  0.97336475]

Model:
(LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=300, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.94889515  0.94314436  0.96886722]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.9488799   0.94315525  0.96888794]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.94885727  0.94315848  0.96886825]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=60, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.9488799   0.94315525  0.96888794]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.94848163  0.94336024  0.97043136]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit two models lol2_1
Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.63214475  0.67346317  0.72360453]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.91908019  0.8797402   0.82903909]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=30,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.94839646  0.93900479  0.97042044]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.63896466  0.80006176  0.96464524]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.55651061  0.86645905  0.96653944]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.55783467  0.84053428  0.96486972]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 2)
Score = [ 0.67891458  0.53941709  0.94395688  0.93465403]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 4)
Score = [ 0.94679385  0.87939535]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 4)
Score = [ 0.9433243   0.95191362]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 2)
Score = [ 0.1698972   0.78083912  0.79199638  0.93029888]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 2)
Score = [ 0.65676849  0.93490183  0.88611446  0.93228705]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=10,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 2)
Score = [ 0.67399205  0.93519548  0.84971106  0.89675686]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=10, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.83794958  0.94222036  0.95982307]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=10, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.52976589  0.55731633  0.51635354]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.95114488  0.92254867  0.8807394 ]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.95235277  0.94428552  0.85260611]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.95166316  0.94337911  0.83538711]

Model:
(LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.94597571  0.91467209  0.89805452]

Model:
(LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 4)
Score = [ 0.94849328  0.91000557]

Model:
(LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit two models lol2_1
Model:
LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 4)
Score = [ 0.93310454  0.94473715]

Model:
(LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=10, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.92821907  0.92763152  0.94086264]

Model:
(LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=20, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.95265188  0.94524443  0.82122847]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.69558437  0.94604903  0.91582798]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=123, solver='auto', tol=0.001))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: score two models with my fold: (7, 3)
Score = [ 0.5644702   0.9424009   0.96497495]

Model:
(LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

----------------------------------------------------------------------------------------------------
Status: submit two models lol2_2
Model:
LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)

Features:
Features_cat_time: is_morning is_day is_evning is_nignt smooth1_hours_0 smooth1_hours_1 smooth1_hours_2 smooth1_hours_3 smooth1_hours_4 smooth1_hours_5 smooth1_hours_6 smooth1_hours_7 smooth1_hours_8 smooth1_hours_9 smooth1_hours_10 smooth1_hours_11 smooth1_hours_12 smooth1_hours_13 smooth1_hours_14 smooth1_hours_15 smooth1_hours_16 smooth1_hours_17 smooth1_hours_18 smooth1_hours_19 smooth1_hours_20 smooth1_hours_21 smooth1_hours_22 smooth1_hours_23 day_0 day_1 day_2 day_3 day_4 day_5 day_6 is_day_off
Features_count_time: month trand_10000_100_1 duration
vecorizer Train+Test: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=8500, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
        stop_words=None, strip_accents=None, sublinear_tf=False,
        token_pattern='[^#]+', tokenizer=None, use_idf=True,
        vocabulary=None)
transformer X_cat_time: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)
scaler for count: StandardScaler(copy=True, with_mean=True, with_std=True)

